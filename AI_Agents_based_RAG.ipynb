{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itdhirendra/IITRoorke_DS_AIML/blob/main/AI_Agents_based_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Program**"
      ],
      "metadata": {
        "id": "HpEu_86YW9w2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhLmpX92W2FQ"
      },
      "outputs": [],
      "source": [
        "# if temperature > desired_temperature:\n",
        "#   turn_on_cooling()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Just follows the fixed rules**\n",
        "* **No consideration of consequences**\n",
        "* **No learning**"
      ],
      "metadata": {
        "id": "jv12t2QgXuQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Responsive Program**"
      ],
      "metadata": {
        "id": "aL7DlENeXYfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if temperature > desired_temperature:\n",
        "#   if time_of_day == \"peak_hours\":\n",
        "#     turn_on_cooling_eco_mode()\n",
        "#   else:\n",
        "#     turn_on_cooling_normal()"
      ],
      "metadata": {
        "id": "Y9FhPFYTXcjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **More complex rules**\n",
        "* **Some context awareness**\n",
        "* **Still no intelligence**"
      ],
      "metadata": {
        "id": "8a7bpB7KX2F3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AI Agents**"
      ],
      "metadata": {
        "id": "Y2OGDdj0YEDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SmartAC:\n",
        "#   def perceive(self):\n",
        "#     curr_temp = get_temperature() # Website Tools\n",
        "#     time = get_time()\n",
        "#     electricity_price = get_curr_electricity_tools()\n",
        "#     weather_forecast = get_forecast()\n",
        "#     user_prefences = get_user_preferences()\n",
        "\n",
        "#     return Enviroment(curr_temp, time, electricity_price, weather_forecast, user_prefences)\n",
        "\n",
        "#   def think(self, enviroment):\n",
        "#     possible_actions = [\n",
        "#         NoAction(),\n",
        "#         CoolNormal(),\n",
        "#         CoolEco(),\n",
        "#         PreCool(),\n",
        "#         TurboMode(),\n",
        "#         WaitforOffPeak()\n",
        "#     ]\n",
        "\n",
        "#   # Evaluate the actions\n",
        "#   best_actions = None\n",
        "#   best_utility = float('-inf')\n",
        "\n",
        "#   for action in possible_actions:\n",
        "#     predicted_outcome = predict_future_outcome(enviroment, action)\n",
        "#     utility = calculate_utility(predicted_outcome)\n",
        "\n",
        "#     if utility > best_utility:\n",
        "#       best_action = action\n",
        "#       best_utility = utility\n",
        "\n",
        "#   return best_action\n",
        "\n",
        "#   def action(self, action):\n",
        "#     action.execute()\n",
        "#     monitor_results()\n",
        "#     update_learning_models()"
      ],
      "metadata": {
        "id": "iWVfoI33X-Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Considering Multiple factors**\n",
        "* **Predicts outcome**\n",
        "* **Learning from experience**\n",
        "* **OPtimizing the long-term goals**\n",
        "* **Balance the objective**"
      ],
      "metadata": {
        "id": "guugxZspaVTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a LangChain Document from Different Files**"
      ],
      "metadata": {
        "id": "VtaYylxEgIa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/PPTs/Session Files/Morning - GenAI/RAG Implementation/Text Data Source/2024_state_of_the_union.txt\") as f:\n",
        "  states_of_union = f.read()"
      ],
      "metadata": {
        "id": "gBn4c-ligx9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/PPTs/Session Files/Morning - GenAI/RAG Implementation/Text Data Source/2024_12_10_Mangione_CBS_Article.txt\") as f:\n",
        "  mangione_cbs_article = f.read()"
      ],
      "metadata": {
        "id": "nnP-wEcRg5DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Requirements**"
      ],
      "metadata": {
        "id": "_F1_E37nhPXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "JXchLCWkhDR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intialize the text splitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        ")"
      ],
      "metadata": {
        "id": "2vlJ4g5EhUa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create documents\n",
        "state_briefing = text_splitter.create_documents([states_of_union])\n",
        "article_docs = text_splitter.create_documents([mangione_cbs_article])"
      ],
      "metadata": {
        "id": "yR9t1dmChYkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT\n",
        "print(\"=====STATE OF UNION BRIEFING=====\")\n",
        "print(f\"LEN: {len(state_briefing)}\")\n",
        "if len(state_briefing) > 0:\n",
        "  print(f\"TYPE: {type(state_briefing[0])}\")\n",
        "  print(f\"\\n{state_briefing[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xajp5za8hw9I",
        "outputId": "360120d7-e26f-4b6a-d2b4-dca97dc7c75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====STATE OF UNION BRIEFING=====\n",
            "LEN: 48\n",
            "TYPE: <class 'langchain_core.documents.base.Document'>\n",
            "\n",
            "page_content='March 07, 2024\n",
            "Remarks of President Joe Biden — State of the Union Address As Prepared for Delivery\n",
            "Home\n",
            "Briefing Room\n",
            "Speeches and Remarks\n",
            "The United States Capitol\n",
            "\n",
            "###\n",
            "\n",
            "Good evening. \n",
            "\n",
            "Mr. Speaker. Madam Vice President. Members of Congress. My Fellow Americans. \n",
            "\n",
            "In January 1941, President Franklin Roosevelt came to this chamber to speak to the nation. \n",
            "\n",
            "He said, “I address you at a moment unprecedented in the history of the Union.” \n",
            "\n",
            "Hitler was on the march. War was raging in Europe. \n",
            "\n",
            "President Roosevelt’s purpose was to wake up the Congress and alert the American people that this was no ordinary moment.   \n",
            "\n",
            "Freedom and democracy were under assault in the world. \n",
            "\n",
            "Tonight I come to the same chamber to address the nation. \n",
            "\n",
            "Now it is we who face an unprecedented moment in the history of the Union. \n",
            "\n",
            "And yes, my purpose tonight is to both wake up this Congress, and alert the American people that this is no ordinary moment either.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT\n",
        "print(\"=====MANGIONE ARTICLE=====\")\n",
        "print(f\"LEN: {len(article_docs)}\")\n",
        "if len(article_docs) > 0:\n",
        "  print(f\"TYPE: {type(article_docs[0])}\")\n",
        "  print(f\"\\n{article_docs[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H1aHfgSiIgd",
        "outputId": "874c48f0-7108-41c2-d33b-3f9380343fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====MANGIONE ARTICLE=====\n",
            "LEN: 18\n",
            "TYPE: <class 'langchain_core.documents.base.Document'>\n",
            "\n",
            "page_content='# What we know about Luigi Mangione, suspect charged in UnitedHealthcare CEO's killing\n",
            "\n",
            "By Alex Sundby, Layla Ferris, Laura Doan, Emma Li, John Doyle\n",
            "Updated on: December 10, 2024 / 8:36 PM EST / CBS News\n",
            "\n",
            "Luigi Mangione has been charged with murder in last week's deadly shooting of UnitedHealthcare CEO Brian Thompson, according to court documents filed Monday night. The 26-year-old, who was identified earlier as a person of interest, was arrested on firearms and other charges in Pennsylvania after being spotted at a McDonald's in Altoona amid a massive manhunt for the shooter.\n",
            "\n",
            "### Here's what we know about Mangione:\n",
            "\n",
            "Luigi Mangione identified as suspect in CEO shooting\n",
            "Police said Tuesday it appears Mangione went to Pittsburgh and then Altoona after leaving New York and that he was dodging surveillance using a signal-blocking bag.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Add the metadata**"
      ],
      "metadata": {
        "id": "S2JagGTWiczl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add metadata for filtering by filename\n",
        "\n",
        "# 2024_state_of_the_union.txt\n",
        "for i, doc in enumerate(state_briefing):\n",
        "  doc.metadata = {\n",
        "      \"filename\": \"2024_state_of_the_union.txt\",\n",
        "      \"chunk\": i + 1\n",
        "  }\n",
        "\n",
        "for i, doc in enumerate(article_docs):\n",
        "  doc.metadata = {\n",
        "      \"filename\" : \"2024_12_10_Mangione_CBS_Article.txt\",\n",
        "      \"chunk\": i+1\n",
        "  }"
      ],
      "metadata": {
        "id": "Ri-Gc7hJiXOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Populate the Local ChromaDB with the Documents**"
      ],
      "metadata": {
        "id": "LNtWl9_0kd58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb langchain_openai langchain_chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLP2HUGtjN3R",
        "outputId": "d5f5591e-e4ea-43b3-f36e-5c8e832ae7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.20.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.44)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.3.13)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
            "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.20.0-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53769 sha256=18ba391b93d478569dbd0483fbd8a06cb0b566c7c8e075edf2cbce885b59a27e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, opentelemetry-instrumentation-fastapi, chromadb, langchain_chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.11 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.1 langchain_chroma-0.2.2 langchain_openai-0.3.8 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.21.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-instrumentation-0.52b0 opentelemetry-instrumentation-asgi-0.52b0 opentelemetry-instrumentation-fastapi-0.52b0 opentelemetry-proto-1.31.0 opentelemetry-util-http-0.52b0 overrides-7.7.0 posthog-3.20.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.46.1 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import os\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "43GUEAyDkpq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"GPt\")"
      ],
      "metadata": {
        "id": "uw8m-oVlllDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Chroma client\n",
        "chroma_client = chromadb.Client()"
      ],
      "metadata": {
        "id": "xuptGcAwli6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collection / Database\n",
        "collection = chroma_client.get_or_create_collection(\"test_collection\")"
      ],
      "metadata": {
        "id": "1WnEAaovlwB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzpab7H7l5pt",
        "outputId": "772a6c93-4d51-4b69-c553-f850f6355d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Collection(name=test_collection)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Embedding model\n",
        "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "yqXw-88El6qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup chroma for vector store\n",
        "vector_store = Chroma(\n",
        "    client = chroma_client,\n",
        "    collection_name = \"test_collection\",\n",
        "    embedding_function= embeddings,\n",
        ")"
      ],
      "metadata": {
        "id": "LiGZ0-YCmE3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the data\n",
        "documents = state_briefing + article_docs"
      ],
      "metadata": {
        "id": "9d6O0SlwmVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = vector_store.add_documents(documents)"
      ],
      "metadata": {
        "id": "aiztL_damh4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Boi0OLo0mk9r",
        "outputId": "3d709e9d-2368-4eba-aa09-299e08511740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for similarity\n",
        "\n",
        "test_results = vector_store.similarity_search(\n",
        "    \"Who is Luigi Magione?\",\n",
        "    k = 3\n",
        ")"
      ],
      "metadata": {
        "id": "hho00VaVmuE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(test_results):\n",
        "  chunk = item.metadata[\"chunk\"]\n",
        "  filename = item.metadata[\"filename\"]\n",
        "\n",
        "  print(f\"====\\nDOCUMENT {i}\")\n",
        "  print(f\"FILENAME: {filename}\")\n",
        "  print(item.page_content+ \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdD-ueYJm6dq",
        "outputId": "6a0bb026-86a6-4b70-8ec3-b0b719a82af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====\n",
            "DOCUMENT 0\n",
            "FILENAME: 2024_12_10_Mangione_CBS_Article.txt\n",
            "Mangione's paternal grandparents, Nicholas and Mary Mangione, were real estate developers who purchased the Turf Valley Country Club in 1978 and Hayfields Country Club in Hunt Valley in 1986. \n",
            "\n",
            "They founded Lorien Health Systems in 1977, and operated WCBM, a Baltimore radio station. Luigi Mangione volunteered at Lorien Health Systems in 2014 while in high school, according to his LinkedIn.\n",
            "\n",
            "Mangione's family said Monday in a statement, \"Unfortunately, we cannot comment on news reports regarding Luigi Mangione. We only know what we have read in the media. Our family is shocked and devastated by Luigi's arrest. We offer our prayers to the family of Brian Thompson and we ask people to pray for all involved. We are devastated by this news.\"\n",
            "\n",
            "### He was valedictorian at the Gilman School in Baltimore\n",
            "\n",
            "\n",
            "====\n",
            "DOCUMENT 1\n",
            "FILENAME: 2024_12_10_Mangione_CBS_Article.txt\n",
            "### He was valedictorian at the Gilman School in Baltimore\n",
            "\n",
            "Mangione graduated in 2016 from the Gilman School, an all-boys private school in Baltimore, according to his LinkedIn account. He was valedictorian for achieving the highest cumulative GPA over four years, according to his LinkedIn page. He captained the Gilman robotics team and also received a scholarship prize in 2014.\n",
            "\n",
            "James Sandberg, a former classmate of Mangione, told CBS Baltimore that, while he wasn't \"particularly close\" with Mangione, he knew him \"somewhat well\" and said, \"He was a nice kid.\"    \n",
            "\n",
            "Sandberg said he was \"shocked\" after someone shared an article naming Mangione as a person of interest in the shooting.\n",
            "\n",
            "\"Thought it was maybe a different Luigi Mangione,\" Sandberg said.\n",
            "\n",
            "Another former classmate, who wishes to remain anonymous out of respect for the Mangione family, told CBS News the two met in middle school and were close throughout high school.\n",
            "\n",
            "\n",
            "====\n",
            "DOCUMENT 2\n",
            "FILENAME: 2024_12_10_Mangione_CBS_Article.txt\n",
            "# What we know about Luigi Mangione, suspect charged in UnitedHealthcare CEO's killing\n",
            "\n",
            "By Alex Sundby, Layla Ferris, Laura Doan, Emma Li, John Doyle\n",
            "Updated on: December 10, 2024 / 8:36 PM EST / CBS News\n",
            "\n",
            "Luigi Mangione has been charged with murder in last week's deadly shooting of UnitedHealthcare CEO Brian Thompson, according to court documents filed Monday night. The 26-year-old, who was identified earlier as a person of interest, was arrested on firearms and other charges in Pennsylvania after being spotted at a McDonald's in Altoona amid a massive manhunt for the shooter.\n",
            "\n",
            "### Here's what we know about Mangione:\n",
            "\n",
            "Luigi Mangione identified as suspect in CEO shooting\n",
            "Police said Tuesday it appears Mangione went to Pittsburgh and then Altoona after leaving New York and that he was dodging surveillance using a signal-blocking bag.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering\n",
        "vector_store.get(where = {\"filename\": \"2024_12_10_Mangione_CBS_Article.txt\"})[\"documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXIwYAucnYG9",
        "outputId": "687d56af-f012-4bf8-cc59-b3321bb4d697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"# What we know about Luigi Mangione, suspect charged in UnitedHealthcare CEO's killing\\n\\nBy Alex Sundby, Layla Ferris, Laura Doan, Emma Li, John Doyle\\nUpdated on: December 10, 2024 / 8:36 PM EST / CBS News\\n\\nLuigi Mangione has been charged with murder in last week's deadly shooting of UnitedHealthcare CEO Brian Thompson, according to court documents filed Monday night. The 26-year-old, who was identified earlier as a person of interest, was arrested on firearms and other charges in Pennsylvania after being spotted at a McDonald's in Altoona amid a massive manhunt for the shooter.\\n\\n### Here's what we know about Mangione:\\n\\nLuigi Mangione identified as suspect in CEO shooting\\nPolice said Tuesday it appears Mangione went to Pittsburgh and then Altoona after leaving New York and that he was dodging surveillance using a signal-blocking bag.\",\n",
              " '\"You can put your phone in there so we can\\'t track your phone,\" Joseph Kenny, chief of detectives for the New York City Police Department, told CBS New York. \"It doesn\\'t transmit a signal, it blocks the signal. In essence, it\\'s like if you wrapped your phone in aluminum foil and put it in a bag.\"\\n\\nBefore Mangione was officially identified as the suspect, NYPD Commissioner Jessica Tisch announced at a news conference Monday afternoon that he was believed to be a person of interest in the shooting.\\n\\nOfficers in Altoona arrested Mangione on unrelated charges at a McDonald\\'s there after a customer alerted an employee who called police, officials said. \"A Pennsylvania resident saw something early this morning at McDonald\\'s and said something to our local police,\" Pennsylvania Gov. Josh Shapiro said, praising the resident as \"a hero.\"\\n\\nThe officers questioned Mangione, who was acting suspiciously, Tisch said.',\n",
              " 'The officers questioned Mangione, who was acting suspiciously, Tisch said.\\n\\nAccording to court documents, the Altoona officers found Mangione sitting at a table in the back of the McDonald\\'s wearing a blue medical mask and looking at a laptop with a backpack on the floor near the table. When the officers asked him to pull the mask down, they recognized him from photos released to the media.\\n\\n\"My partner and I recognized him immediately,\" Altoona Patrolman Tyler Frye told reporters during a news conference Monday night. \"Just from what we saw in the media, with photos, videos, we just didn\\'t even think twice about it, we knew that was our guy.\"\\n\\nMangione was carrying multiple fraudulent IDs and a U.S. passport, Tisch said. One of the IDs matched the fake New Jersey ID that the shooting suspect used to check into a Manhattan hostel before the shooting, the commissioner said.',\n",
              " 'When the Altoona officers asked Mangione for his ID at the McDonald\\'s, he gave them the New Jersey ID, according to an affidavit submitted with a criminal complaint. When one officer was checking the ID with dispatchers, the other asked Mangione if he had been to New York recently, and Mangione \"became quiet and started to shake,\" according to the affidavit.\\n\\n\"That really invoked a physical reaction from the suspect,\" Altoona Deputy Police Chief Derek Swope told reporters Monday night. \"He became visibly nervous, kind of shaking at that question, and he didn\\'t really answer it directly, so that statement alone really said a lot, and the suspect didn\\'t have to say a lot after that question to show that, you know, he was very nervous at that point.\"\\n\\nMangione provided his real name after he was told he would be arrested if he lied about his identity, according to the affidavit. When an officer asked Mangione why he lied about his name, he allegedly said, \"I clearly shouldn\\'t have.\"',\n",
              " \"Officers found a gun and a suppressor that were consistent with the weapon used in the Dec. 4 shooting of Thompson, Tisch said. Police said the gun found in his backpack appeared to be a 3D-printed ghost gun, with a loaded Glock magazine with six 9 mm full metal jacket rounds. Clothing and a mask consistent with those of the suspect in the case were also recovered, police said.\\n\\nMangione was charged Monday evening with five counts in Pennsylvania: forgery, firearms not to be carried without a license, tampering with records or identification, possessing instruments of crime, and false identification to law enforcement.\\n\\nPennsylvania State Police Lt. Col. George Bivens said Mangione was initially cooperative and then stopped cooperating with investigators. He wasn't aware of Mangione having a criminal history.\\n\\n### Held without bail at hearing, fighting extradition\",\n",
              " '### Held without bail at hearing, fighting extradition\\n\\nAt an extradition proceeding on Tuesday afternoon in Pennsylvania, Mangione was denied bail. He is contesting extradition, and Pennsylvania has 30 days to get a warrant from New York Gov. Kathy Hochul to start the process.\\n\\nA defense attorney for Mangione, Thomas Dickey, argued that the state of New York did not provide the defense with the official second-degree murder charges in documents they were given and now the defense has 14 days to request a writ of habeas corpus for those. In New York, the office of Manhattan District Attorney Alvin Bragg confirmed to CBS News that prosecutors will seek a governor\\'s warrant to secure Mangione\\'s extradition to Manhattan.\\n\\nAs Mangione entered the Blair County Courthouse ahead of Tuesday\\'s proceedings, he was aggressive and had to be contained, shouting that what was happening to him was \"an insult to the intelligence of the American people.\"',\n",
              " 'At his office Tuesday evening, Dickey told reporters he hadn\\'t seen video footage of Mangione\\'s outburst but said, \"Hopefully, there won\\'t be any more of that.\"\\n\\nDickey said he was hired to represent Mangione and not appointed to the case. He wouldn\\'t identify who hired him, and he wouldn\\'t comment on what Mangione has said to him.\\n\\nDickey said Mangione will plead not guilty to the Pennsylvania charges, and said he\\'d advise Mangione to enter the same plea to the New York charges. Asked to clarify what specific charges Mangione would plead not guilty to, Dickey said, \"Every charge.\"\\n\\n\"Remember — and this is not just a small thing — the fundamental concept of American justice is the presumption of innocence and until you\\'re proven guilty beyond a reasonable doubt, and I\\'ve seen zero evidence at this point,\" Dickey said.\\n\\n### Police say Mangione had handwritten note expressing views',\n",
              " '### Police say Mangione had handwritten note expressing views\\n\\nA handwritten document that \"speaks to both his motivation and mindset\" was also recovered from Mangione when he was apprehended by police, according to Tisch. \\n\\nIn the three-page note, Mangione attempted to justify his actions, police said. NYPD sources referred to the notes as a claim of responsibility. \\n\\nMangione wrote that the U.S. had \"most expensive healthcare system in the world\" but lamented that the country \"ranks #42 in life expectancy,\" according to NYPD sources. Intelligence officers within the NYPD believe Mangione\\'s grievances about UnitedHealthcare and other health insurance companies motivated the murder, NYPD sources said.',\n",
              " 'Mangione also referred to corporations as \"mafiosa [that] have gotten too powerful,\" and said such companies abuse the United States \"for immense profit.\" He wrote that others had shone a light on corporations\\' \"corruption and greed\" in the past and claimed that he was \"the first to face it with such brutal honesty.\" \\n\\nNYPD intelligence officers believe Mangione might have been inspired by \"Unabomber\" Ted Kaczynski, with the handwritten note reflecting a similar mindset. \\n\\nKenny told reporters that officials \"don\\'t think that there\\'s any specific threats to other people mentioned in that document,\" but NYPD sources said police are concerned about the risk of extremists viewing Mangione as an example to follow. Shapiro expressed this concern in his Monday remarks, and strongly condemned both the murder and those who celebrated it online. \\n\\n\"The suspect is a coward, not a hero,\" Shapiro said. \\n\\n### He worked at TrueCar, has Ivy League degree',\n",
              " '\"The suspect is a coward, not a hero,\" Shapiro said. \\n\\n### He worked at TrueCar, has Ivy League degree\\n\\nAccording to his LinkedIn account, Mangione worked as a data engineer at the car-buying website TrueCar. But a company spokesperson told CBS News that Mangione hasn\\'t worked there since 2023.\\n\\nMangione graduated from the University of Pennsylvania in 2020, a Penn spokesperson confirmed to CBS News. He received a Master of Science in engineering with a major in computer and information science, and a Bachelor of Science in engineering, majoring in computer science with a minor in mathematics, the spokesperson confirmed.\\n\\nWhile at Penn, he worked as a teaching assistant and founded a video game development club, according to his LinkedIn account.\\n\\nAt Stanford University in California, Mangione was a head counselor for a pre-collegiate studies program during the summer of 2019, the university said in a statement to CBS News.\\n\\n### He has ties to Honolulu',\n",
              " '### He has ties to Honolulu\\n\\nMangione\\'s last known address was in Honolulu, Hawaii, Kenny told reporters. According to an Instagram video posted by the Surfbreak coliving community, Mangione had been living there at some point. \\n\\n\"We are aware that Luigi Mangione was a resident at the Surfbreak co-living\\'s Honolulu location in 2022,\" Surfbreak told CBS News in a statement. \"His alleged actions do not reflect the individual we knew, the values of Surfbreak as an organization, or our community. Reasonable people may disagree but violence is never the answer.\"  \\n\\nSarah Nehemiah, who knew Mangione during his time living at a co-living/working space called Surfbreak in Honolulu, said he left the community in April 2022 due to a lifelong back injury exacerbated by physical activity on the island.',\n",
              " '\"Mangione lived at Surfbreak from January 2022 until April of that year. It was our understanding that he left due to a lifelong back injury that was exacerbated by surfing and hiking. To our knowledge, nearly all members of Surfbreak from his tenure lost contact after he left. To our knowledge, he did return to Hawaii briefly in early 2023 and started a book club. Several members left due to discomfort in book choices,\" said Nehemiah, who says she is now acting as a spokesperson for several members of the community.\\n\\nA second source familiar with Mangione\\'s stay at Surfbreak said back pain was a major theme of his life at that time. He tried to surf in Hawaii and was not able to. This appeared to be a source of pain and frustration for him, said the source.',\n",
              " \"The background image on Mangione's X account shows an X-ray of a spine with hardware in it, reflective of previous surgery. It is not known if this is an X-ray of Mangione's spine. An orthopedist told CBS News that the image appeared to show a hardware fusion likely for spondylolisthesis.\\n\\n### He's related to a prominent Maryland family\\n\\nMangione was born and raised in Maryland, Kenny said. He is related to a prominent Maryland family that owns country clubs, health care facilities and real estate companies, CBS News Baltimore reported. He's also a cousin of Maryland state Delegate Nino Mangione, who represents parts of Baltimore County.\\n\\nMangione's paternal grandparents, Nicholas and Mary Mangione, were real estate developers who purchased the Turf Valley Country Club in 1978 and Hayfields Country Club in Hunt Valley in 1986.\",\n",
              " 'Mangione\\'s paternal grandparents, Nicholas and Mary Mangione, were real estate developers who purchased the Turf Valley Country Club in 1978 and Hayfields Country Club in Hunt Valley in 1986. \\n\\nThey founded Lorien Health Systems in 1977, and operated WCBM, a Baltimore radio station. Luigi Mangione volunteered at Lorien Health Systems in 2014 while in high school, according to his LinkedIn.\\n\\nMangione\\'s family said Monday in a statement, \"Unfortunately, we cannot comment on news reports regarding Luigi Mangione. We only know what we have read in the media. Our family is shocked and devastated by Luigi\\'s arrest. We offer our prayers to the family of Brian Thompson and we ask people to pray for all involved. We are devastated by this news.\"\\n\\n### He was valedictorian at the Gilman School in Baltimore',\n",
              " '### He was valedictorian at the Gilman School in Baltimore\\n\\nMangione graduated in 2016 from the Gilman School, an all-boys private school in Baltimore, according to his LinkedIn account. He was valedictorian for achieving the highest cumulative GPA over four years, according to his LinkedIn page. He captained the Gilman robotics team and also received a scholarship prize in 2014.\\n\\nJames Sandberg, a former classmate of Mangione, told CBS Baltimore that, while he wasn\\'t \"particularly close\" with Mangione, he knew him \"somewhat well\" and said, \"He was a nice kid.\"    \\n\\nSandberg said he was \"shocked\" after someone shared an article naming Mangione as a person of interest in the shooting.\\n\\n\"Thought it was maybe a different Luigi Mangione,\" Sandberg said.\\n\\nAnother former classmate, who wishes to remain anonymous out of respect for the Mangione family, told CBS News the two met in middle school and were close throughout high school.',\n",
              " 'Another former classmate, who wishes to remain anonymous out of respect for the Mangione family, told CBS News the two met in middle school and were close throughout high school.\\n\\n\"He was a nice guy, a smart guy. I wouldn\\'t characterize him as introverted or extroverted. He didn\\'t have any enemies,\" the former classmate said. \"He was our valedictorian for a reason.\"\\n\\nWhen they heard about the news of Mangione being a person of interest, the former classmate said they felt sympathetic to the situation.\\n\\n\"I don\\'t think he is a crazy person,\" the former classmate said. \"I hope that there\\'s a public trial and he gets the chance to explain how all of this happened in court.\" \\n\\nThe former classmate said the two lost touch after high school, but they remember Mangione being a \"good guy.\"\\n\\n### People sent him messages on social media before his arrest',\n",
              " 'The former classmate said the two lost touch after high school, but they remember Mangione being a \"good guy.\"\\n\\n### People sent him messages on social media before his arrest\\n\\nIn the months leading up to Mangione\\'s arrest, posts tagging his account on the social media platform X indicate his friends may have been trying to contact him.\\n\\n\"Nobody has heard from you in months,\" one post from October read.\\n\\nAnother post from July read, \"I don\\'t know if you are okay or just in a super isolated place and have no service. But I haven\\'t heard from you in months.\"\\n\\n### He had an account on Goodreads\\n\\nOn the Goodreads website, Mangione\\'s account contained a four-star rating and review of \"Industrial Society and Its Future,\" written by Theodore John Kaczynski, also known as the Unabomber. Two health care-related books are on his read tab from 2022, including \"Crooked: Outwitting the Back Pain Industry and Getting on the Road to Recovery\" and \"Back Mechanic.\"',\n",
              " 'Mangione\\'s X account reposted the quote, \"It is no measure of health to be well-adjusted to a profoundly sick society,\" by J. Krishnamurti at least twice, most recently in January 2024.']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agentic LLM Tools**"
      ],
      "metadata": {
        "id": "KZeMrVLrn4RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "wZSUuizknvfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool for getting the files\n",
        "def get_file_list() -> List[str]:\n",
        "  \"\"\"\n",
        "  Retrive a list of all the files that are present or that are currently available to the users\n",
        "  Args: None\n",
        "  \"\"\"\n",
        "  return [\"2024_12_10_Mangione_CBS_Article.txt\", \"2024_state_of_the_union.txt\"]"
      ],
      "metadata": {
        "id": "a7hfBOIDn8TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tools for reading the files\n",
        "def get_file_content_by_name(filename: str) -> str:\n",
        "  \"\"\"\n",
        "  Retrieve the data for a specific file that will be provided by the user\n",
        "  Args:filename\n",
        "  \"\"\"\n",
        "  valid_files = [\"2024_12_10_Mangione_CBS_Article.txt\", \"2024_state_of_the_union.txt\"]\n",
        "  if (filename not in valid_files):\n",
        "    return \"ERROR: NOT A VALID FILE NAME PROVIDED! TRY AGAIN!!!\"\n",
        "\n",
        "  # GEt the content from the vector DB\n",
        "  content_list = vector_store.get(where = {\"filename\": filename})[\"documents\"]\n",
        "  content = \"\\n\".join(content_list)\n",
        "\n",
        "  return content"
      ],
      "metadata": {
        "id": "QCDFJ15eoRsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG\n",
        "def default_rag(query: str) -> str:\n",
        "  \"\"\"\n",
        "  Search the vectorDB for a relevant doc for information on the query\n",
        "\n",
        "  Args: users' query\n",
        "  \"\"\"\n",
        "\n",
        "  test_results = vector_store.similarity_search(\n",
        "    query,\n",
        "    k = 3 # # document with most relevnet contentn\n",
        "  )\n",
        "  content_list = [f\"* {res.page_content} [{res.metadata}]\" for res in test_results]\n",
        "  content = \"\\n\".join(content_list)\n",
        "  return content"
      ],
      "metadata": {
        "id": "lUcAERdjpNFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BIND THEM TOGETHER\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
        "\n",
        "# GEt my tools\n",
        "tools = [get_file_list, get_file_content_by_name, default_rag]\n",
        "\n",
        "# Bind the tools with LLM\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "7uzJieD-qLKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create a Reasoner**"
      ],
      "metadata": {
        "id": "h6PlSFymqm8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "xsZBimgtqmDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reasoner(state):\n",
        "  query = state[\"query\"]\n",
        "  # maintain the conversation the history\n",
        "  messages = state[\"message\"]\n",
        "\n",
        "  # System Message\n",
        "  sys_msg = \"You are a helpful AI Agent Assistant. You check tools and decide which tool to use based on the user's query. They can either summarize a single file or search across all the files for the RAG profiles. based on context returned, you will answer the query to the best of your abilities\"\n",
        "\n",
        "  # update the message\n",
        "  message = HumanMessage(query)\n",
        "  messages.append(message)\n",
        "  results = [llm_with_tools.invoke([sys_msg] + messages)]\n",
        "  return {\"Messages\": results}"
      ],
      "metadata": {
        "id": "TQZLp2vpqvoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangGraph**"
      ],
      "metadata": {
        "id": "9Pmqy_L1r66s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsXRxdoNrwGx",
        "outputId": "1c3069d5-0ec9-4863-e3c5-f64ee3de260f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.11-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.44)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.20-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.57-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.11-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.20-py3-none-any.whl (39 kB)\n",
            "Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.57-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.11 langgraph-checkpoint-2.0.20 langgraph-prebuilt-0.1.3 langgraph-sdk-0.1.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZR2-XwcJr-T-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}